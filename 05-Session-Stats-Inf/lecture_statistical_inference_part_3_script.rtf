{\rtf1\deff0{\fonttbl{\f0 Calibri;}{\f1 Times New Roman;}{\f2 Arial;}}{\colortbl\red0\green0\blue0 ;\red0\green0\blue255 ;}{\*\defchp \f1}{\*\listoverridetable}{\stylesheet {\ql\f1 Normal;}{\*\cs1\f1 Default Paragraph Font;}{\*\cs2\sbasedon1\f1 Line Number;}{\*\cs3\ul\f1\cf1 Hyperlink;}{\*\ts4\tsrowd\f1\ql\trautofit1\tscellpaddfl3\tscellpaddl108\tscellpaddfr3\tscellpaddr108\tsvertalt\cltxlrtb Normal Table;}{\*\ts5\tsrowd\sbasedon4\f1\ql\trbrdrt\brdrs\brdrw10\trbrdrl\brdrs\brdrw10\trbrdrb\brdrs\brdrw10\trbrdrr\brdrs\brdrw10\trbrdrh\brdrs\brdrw10\trbrdrv\brdrs\brdrw10\trautofit1\tscellpaddfl3\tscellpaddl108\tscellpaddfr3\tscellpaddr108\tsvertalt\cltxlrtb Table Simple 1;}}\nouicompat\splytwnine\htmautsp\sectd\pard\plain\ql{\f2\cf0 1}\f2\cf0\par\pard\plain\ql{\f2\cf0 this is part three of the lecture on statistical inference for linear regression. We will go through }{\lang1033\langfe1033\f2\cf0 a}{\f2\cf0  numerical example of the statistical test}{\lang1033\langfe1033\f2\cf0  for regression coefficient}{\f2\cf0 .}{\lang1033\langfe1033\f2\cf0  }\lang1033\langfe1033\f2\cf0\par\pard\plain\ql\f2\cf0\par\pard\plain\ql{\f2\cf0 2}\f2\cf0\par\pard\plain\ql{\f2\cf0 linear regression of systolic blood pressure on gende}{\f2\cf0 r}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  age}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  and education}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  was done. Let's look at results related to x3, which is the binary variable for high school graduates.}{\lang1033\langfe1033\f2\cf0  .}{\f2\cf0  }{\lang1033\langfe1033\f2\cf0 B}{\f2\cf0 3,  the estimated regression coefficient for}{\lang1033\langfe1033\f2\cf0  }{\f2\cf0 x3, was -1.28882, }{\lang1033\langfe1033\f2\cf0 and }{\f2\cf0 s3, the estimated standard error for b3, was 0.64192. So the test statistics, t3, which is the ratio of b3 to s3, is }{\f2\cf0 -1.28882}{\lang1033\langfe1033\f2\cf0  over }{\f2\cf0 0.64192}{\lang1033\langfe1033\f2\cf0 , which is }{\f2\cf0 approximately -2.01.}\f2\cf0\par\pard\plain\ql{\f2\cf0 the null }{\f2\cf0 hypothesis is that, beta 3,  the }{\lang1033\langfe1033\f2\cf0 true}{\f2\cf0  value of regression coefficient for x3, equals zero. }\f2\cf0\par\pard\plain\ql{\f2\cf0 It can be shown, using the t distribution, that if beta  3  is zero, then the probability that t3  is greater than or equal to 2.01, or t3  is smaller than or equal to -2.01}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  is 0.0447. We can also say}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  the probability that the absolute value of t3 is greater than or equal to 2.01}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  is 0.0447. This 0.0447 is the P value of b3}{\f2\cf0  by the two-sided test.}\f2\cf0\par\pard\plain\ql\f2\cf0\par\pard\plain\ql\f2\cf0\par\pard\plain\ql{\f2\cf0 3}\f2\cf0\par\pard\plain\ql{\f2\cf0 this graph shows how the P value was obtained. This is a graph of T distribution}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  with the degree of freedom of 4025. Based on some mathematical assumptions, }{\lang1033\langfe1033\f2\cf0 it can be shown that, }{\f2\cf0 if the null hypothesis is true, that is, i}{\lang1033\langfe1033\f2\cf0 f}{\f2\cf0  beta three is zero, then the test statistics, t3,}{\lang1033\langfe1033\f2\cf0  }{\lang1033\langfe1033\f2\cf0 asymtotically }{\f2\cf0  follows this t distribution. Not all }{\lang1033\langfe1033\f2\cf0 t}{\f2\cf0  distributions are identical. This is the t distribution with the degree of freedom of 4025}{\lang1033\langfe1033\f2\cf0 . The degree of freedom}{\f2\cf0  }{\lang1033\langfe1033\f2\cf0 was determined as}{\f2\cf0  the number of cases, 4030, }{\lang1033\langfe1033\f2\cf0 minus}{\f2\cf0  the number of independent variables, which is four}{\lang1033\langfe1033\f2\cf0 , minus one}{\f2\cf0 .}{\lang1033\langfe1033\f2\cf0  The t-distribution with a high degree of freedom is almost identical to the normal distribution.}\f2\cf0\par\pard\plain\ql{\f2\cf0 The horizontal axis indicates values of T, and the area under the curve over a certain range on the }{\lang1033\langfe1033\f2\cf0 horizontal}{\f2\cf0  axis represents the probability that t falls in the range. The area under the entire curve is one. }\f2\cf0\par\pard\plain\ql{\f2\cf0 The computed value of t3, -2.01, is indicated }{\lang1033\langfe1033\f2\cf0 on the horizontal axis}{\f2\cf0 .  }{\lang1033\langfe1033\f2\cf0 T}{\f2\cf0 he red area on the }{\lang1033\langfe1033\f2\cf0 left}{\f2\cf0  of -2.01}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  is 2.235% of the entire area under the curve,  which means that if the n}{\lang1033\langfe1033\f2\cf0 ull}{\f2\cf0  hypothesis is true, the probability that t3 is less than or equal to -}{\lang1033\langfe1033\f2\cf0 2}{\f2\cf0 .01}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  is 2.235%. }\f2\cf0\par\pard\plain\ql{\f2\cf0 There is another red area, which is on the right of +2.01. Since th}{\lang1033\langfe1033\f2\cf0 e t distribution }{\f2\cf0 curve is symmetric}{\lang1033\langfe1033\f2\cf0  around 0}{\f2\cf0 , the red area }{\lang1033\langfe1033\f2\cf0 on the right side }{\f2\cf0 shows that}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  if the n}{\lang1033\langfe1033\f2\cf0 ull}{\f2\cf0  hypothesis is true, the probability that t3 Is greater than or equal to 2.01}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  is }{\f2\cf0 2.235% }{\lang1033\langfe1033\f2\cf0 as well}{\f2\cf0 . Combining the two red areas together, this graph shows that, if beta  3 is zero , the probability that the absolute value of t3 is greater than or equal to 2.01}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  is 4.47% or 0.0447 .}\f2\cf0\par\pard\plain\ql{\f2\cf0 This is the P value by the two-sided test and the P value by the one-sided test is shown by }{\lang1033\langfe1033\f2\cf0 the}{\f2\cf0  red area}{\lang1033\langfe1033\f2\cf0  on the right side}{\f2\cf0 , which is 0.02}{\lang1033\langfe1033\f2\cf0 2}{\f2\cf0 35. }\f2\cf0\par\pard\plain\ql{\lang1033\langfe1033\f2\cf0 In this section, }{\lang1033\langfe1033\f2\cf0 w}{\lang1033\langfe1033\f2\cf0 e }{\lang1033\langfe1033\f2\cf0 mainly }{\lang1033\langfe1033\f2\cf0 follow }{\lang1033\langfe1033\f2\cf0 the }{\lang1033\langfe1033\f2\cf0 standard }{\lang1033\langfe1033\f2\cf0 procedure of }{\lang1033\langfe1033\f2\cf0 two-sided test}{\lang1033\langfe1033\f2\cf0  }{\lang1033\langfe1033\f2\cf0 of}{\lang1033\langfe1033\f2\cf0  regression coefficients}{\lang1033\langfe1033\f2\cf0  for linear regression}{\lang1033\langfe1033\f2\cf0 , }{\lang1033\langfe1033\f2\cf0 because the two-sided test}{\lang1033\langfe1033\f2\cf0  is more widely used}{\lang1033\langfe1033\f2\cf0 ,}{\lang1033\langfe1033\f2\cf0  than the one-sided tes}{\lang1033\langfe1033\f2\cf0 t}{\lang1033\langfe1033\f2\cf0 . The mechanics of the one-sided test is }{\lang1033\langfe1033\f2\cf0 essentially the same}{\lang1033\langfe1033\f2\cf0 , }{\lang1033\langfe1033\f2\cf0 and }{\lang1033\langfe1033\f2\cf0 the p value by the one-sided test is always a half of the p value by the corresponding two-sided test, }{\lang1033\langfe1033\f2\cf0 due to the symmetry around 0 of}{\lang1033\langfe1033\f2\cf0  the t-distribution}{\lang1033\langfe1033\f2\cf0 .}\f2\cf0\par\pard\plain\ql\f2\cf0\par\pard\plain\ql{\f2\cf0 4}\f2\cf0\par\pard\plain\ql{\lang1033\langfe1033\f2\cf0 T}{\f2\cf0 his slide shows a}{\lang1033\langfe1033\f2\cf0  }{\f2\cf0 part of computer output of the regression analysis. This is not a sass output,  but  formats of output of regression analysis are similar }{\lang1033\langfe1033\f2\cf0 among}{\f2\cf0   various  statistical programs. Let's look at the row marked as HS, }{\lang1033\langfe1033\f2\cf0 indicating}{\f2\cf0  those who have graduated from high school, but not from college. It is shown in the row}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  that, B, the estimated value of regression coefficient for the binary variable, HS, is }{\lang1033\langfe1033\f2\cf0 -}{\f2\cf0 1.28882,  and S, the estimated standard error }{\lang1033\langfe1033\f2\cf0 of}{\f2\cf0  B, is 0.64192.  It is }{\f2\cf0 shown}{\lang1033\langfe1033\f2\cf0  in the next column,}{\f2\cf0  that, T, the ratio of B to S, is -}{\lang1033\langfe1033\f2\cf0 2.0}{\f2\cf0 1, and in the rightmost column, the p-value, the probability }{\f2\cf0 for the absolute value of T to be greater than 2.01, is shown to be 0.0447. The p-value is smaller than 0.05, i.e., the value of B is statistically significantly different from zero at the 0.05 level.}\f2\cf0\par\pard\plain\ql\f2\cf0\par\pard\plain\ql{\f2\cf0 5}\f2\cf0\par\pard\plain\ql{\f2\cf0 the test statistic}{\f2\cf0  T}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  follows the t-distribution with the degree of freedom of }{\lang1033\langfe1033\f2\cf0 [}{\f2\cf0 n}{\lang1033\langfe1033\f2\cf0  minus }{\f2\cf0 k}{\lang1033\langfe1033\f2\cf0  minus}{\f2\cf0 1}{\lang1033\langfe1033\f2\cf0 ]}{\lang1033\langfe1033\f2\cf0 , where}{\lang1033\langfe1033\f2\cf0  }{\lang1033\langfe1033\f2\cf0 [}{\lang1033\langfe1033\f2\cf0  n}{\lang1033\langfe1033\f2\cf0 ]}{\lang1033\langfe1033\f2\cf0  is the number of cases and }{\lang1033\langfe1033\f2\cf0 [}{\lang1033\langfe1033\f2\cf0 k}{\lang1033\langfe1033\f2\cf0 ]}{\lang1033\langfe1033\f2\cf0  is the number of independent variables}{\f2\cf0 . This makes it possible to comput}{\f2\cf0 e}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  not only the P value}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  but also }{\f2\cf0 confidence intervals for beta, }{\lang1033\langfe1033\f2\cf0 that is, confidence interfal}{\lang1033\langfe1033\f2\cf0 s}{\lang1033\langfe1033\f2\cf0  for }{\f2\cf0 the true value of the regression coefficient. In order to compute a confidence interval, we need to specify a level of probability for the confidence interval, such as 99% confidence interval, 95% confidence interval, and 90% confidence interval. Let }{\lang1033\langfe1033\f2\cf0 [}{\f2\cf0 q}{\lang1033\langfe1033\f2\cf0 ]}{\f2\cf0  be}{\lang1033\langfe1033\f2\cf0  a value, in }{\lang1033\langfe1033\f2\cf0 %}{\lang1033\langfe1033\f2\cf0 , of}{\f2\cf0  probability}{\f2\cf0 . So a }{\lang1033\langfe1033\f2\cf0 q}{\f2\cf0  % confidence interval for beta means}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  that the probability for beta to be in the interval}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  is }{\lang1033\langfe1033\f2\cf0 [}{\f2\cf0 q}{\lang1033\langfe1033\f2\cf0 ]}{\f2\cf0  %.}\f2\cf0\par\pard\plain\ql{\lang1033\langfe1033\f2\cf0 Now l}{\lang1033\langfe1033\f2\cf0 et's }{\lang1033\langfe1033\f2\cf0 follow}{\lang1033\langfe1033\f2\cf0 , as an example, }{\lang1033\langfe1033\f2\cf0 the}{\f2\cf0  }{\lang1033\langfe1033\f2\cf0 computation of }{\lang1033\langfe1033\f2\cf0 the }{\f2\cf0 95% confidence interval for beta for high school graduates}{\f2\cf0 .}\f2\cf0\par\pard\plain\ql\f2\cf0\par\pard\plain\ql{\f2\cf0 6. }\f2\cf0\par\pard\plain\ql{\lang1033\langfe1033\f2\cf0 We start with}{\f2\cf0  the general formula for T, i.e.,  T is the difference between B and beta, divided by S. }{\lang1033\langfe1033\f2\cf0 . }{\f2\cf0 This T }{\lang1033\langfe1033\f2\cf0 asymptotically}{\f2\cf0  follows the t-distribution with a given degree of freedom, which is 4025 in this }{\lang1033\langfe1033\f2\cf0 case}{\f2\cf0 . This is a graph of the t-distribution. }{\lang1033\langfe1033\f2\cf0 The horizontal axis represent}{\lang1033\langfe1033\f2\cf0 s}{\lang1033\langfe1033\f2\cf0  values of T}{\lang1033\langfe1033\f2\cf0 , and the vertical axis }{\lang1033\langfe1033\f2\cf0 i}{\lang1033\langfe1033\f2\cf0 s }{\lang1033\langfe1033\f2\cf0 related to their probabilities}{\lang1033\langfe1033\f2\cf0 . }{\lang1033\langfe1033\f2\cf0 Two values of t, }{\lang1033\langfe1033\f2\cf0 +}{\lang1033\langfe1033\f2\cf0 1.961 and -1.961, are indicated on the horizontal axis. }{\f2\cf0 The red area on the right of  }{\lang1033\langfe1033\f2\cf0 +}{\f2\cf0 1.961 is 2.5% }{\f2\cf0 of the entire area under the curve. So is the red area on the left of }{\f2\cf0 -1.961. This means the probability that T is greater than or equal to }{\lang1033\langfe1033\f2\cf0 +}{\f2\cf0 1.961 is 2.5%, and so is the probability that T is smaller than or equal to -1.961. Therefore, the probability that T is between -1.961 and }{\lang1033\langfe1033\f2\cf0 +}{\f2\cf0 1.961}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  is 95%.}\f2\cf0\par\pard\plain\ql\f2\cf0\par\pard\plain\ql{\f2\cf0 7}\f2\cf0\par\pard\plain\ql{\lang1033\langfe1033\f2\cf0 S}{\lang1033\langfe1033\f2\cf0 uppose}{\lang1033\langfe1033\f2\cf0  }{\lang1033\langfe1033\f2\cf0 t}{\lang1033\langfe1033\f2\cf0 , }{\lang1033\langfe1033\f2\cf0 or }{\lang1033\langfe1033\f2\cf0 lower-case t,}{\lang1033\langfe1033\f2\cf0  is a quantity, the probability distri}{\lang1033\langfe1033\f2\cf0 bution of which }{\f2\cf0 follows the t-distribution}{\lang1033\langfe1033\f2\cf0  with the degree of freedom of 4025}{\lang1033\langfe1033\f2\cf0 . Then }{\f2\cf0 the probability that the }{\lang1033\langfe1033\f2\cf0 lower-case}{\f2\cf0  T}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  falls between -1.961  and }{\lang1033\langfe1033\f2\cf0 +}{\f2\cf0 1.961}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  is 95%, or 0.95. }{\lang1033\langfe1033\f2\cf0 It can also be shown that, }{\lang1033\langfe1033\f2\cf0 the }{\lang1033\langfe1033\f2\cf0 upper-case}{\f2\cf0  T, }{\lang1033\langfe1033\f2\cf0 which is }{\f2\cf0 a test statistic obtained from the results of the regression analysis, }{\lang1033\langfe1033\f2\cf0 as}{\lang1033\langfe1033\f2\cf0 y}{\lang1033\langfe1033\f2\cf0 mptotically }{\f2\cf0 follows the t distribution}{\lang1033\langfe1033\f2\cf0 . }{\lang1033\langfe1033\f2\cf0 Then, }{\f2\cf0 the probability that the large T falls between -1.961  and }{\lang1033\langfe1033\f2\cf0 +}{\f2\cf0 1.961}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  is about 95%. By }{\lang1033\langfe1033\f2\cf0 replacing the }{\lang1033\langfe1033\f2\cf0 upper-case }{\f2\cf0 T}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  }{\lang1033\langfe1033\f2\cf0 by [}{\f2\cf0  (B minus beta) }{\lang1033\langfe1033\f2\cf0 over}{\f2\cf0  S}{\lang1033\langfe1033\f2\cf0  ] }{\f2\cf0 and rearranging the terms, we get }{\lang1033\langfe1033\f2\cf0 that }{\f2\cf0 the probability for beta}{\f2\cf0  to fall between (B minus 1.961 times S)  and (B plus}{\f2\cf0  1.961 times S)}{\lang1033\langfe1033\f2\cf0 , }{\f2\cf0 is }{\lang1033\langfe1033\f2\cf0 about}{\f2\cf0  95%}{\lang1033\langfe1033\f2\cf0 , too}{\f2\cf0 . So these two quantities}{\lang1033\langfe1033\f2\cf0 , }{\f2\cf0  }{\f2\cf0 (B minus 1.961 times S)  and (B plus 1.961 times S)}{\lang1033\langfe1033\f2\cf0 ,}{\lang1033\langfe1033\f2\cf0  }{\f2\cf0 are the lower and higher ends of a 95% confidence interval for beta.}\f2\cf0\par\pard\plain\ql{\f2\cf0 In the example of beta coefficient for high school graduates, B3 was -1.289}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  and s3 was 0.642. Substituting these numbers into the equation, we get the range between -2.547 and -0.030 as }{\lang1033\langfe1033\f2\cf0 the}{\f2\cf0  95% confidence interval for beta 3.}\f2\cf0\par\pard\plain\ql{\lang1033\langfe1033\f2\cf0 By the way, although}{\f2\cf0  }{\lang1033\langfe1033\f2\cf0 we can get many}{\f2\cf0  95% confidence intervals}{\lang1033\langfe1033\f2\cf0  for beta 3}{\lang1033\langfe1033\f2\cf0 , this }{\f2\cf0 is }{\lang1033\langfe1033\f2\cf0 the only}{\f2\cf0  95% interval that }{\lang1033\langfe1033\f2\cf0 is}{\f2\cf0  centered at }{\lang1033\langfe1033\f2\cf0 B,}{\lang1033\langfe1033\f2\cf0  }{\lang1033\langfe1033\f2\cf0 which is -1.289}{\f2\cf0 .}{\lang1033\langfe1033\f2\cf0  We usually get the 95% confid}{\lang1033\langfe1033\f2\cf0 nce interval }{\lang1033\langfe1033\f2\cf0 for beta}{\lang1033\langfe1033\f2\cf0 ,}{\lang1033\langfe1033\f2\cf0  that is }{\lang1033\langfe1033\f2\cf0 centered at }{\lang1033\langfe1033\f2\cf0 B.}\lang1033\langfe1033\f2\cf0\par\pard\plain\ql{\f2\cf0 So}{\lang1033\langfe1033\f2\cf0 , now we }{\lang1033\langfe1033\f2\cf0 understand that}{\f2\cf0  }{\f2\cf0 computation of }{\lang1033\langfe1033\f2\cf0 the }{\lang1033\langfe1033\f2\cf0 test ststistic }{\f2\cf0 T from results of regression analysis}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  and }{\lang1033\langfe1033\f2\cf0 placing}{\f2\cf0  }{\f2\cf0 the value of T }{\lang1033\langfe1033\f2\cf0 in}{\f2\cf0  the t distribution}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  }{\lang1033\langfe1033\f2\cf0 produce }{\f2\cf0 both }{\lang1033\langfe1033\f2\cf0 the }{\f2\cf0 p-value}{\lang1033\langfe1033\f2\cf0  for B}{\f2\cf0  and confidence intervals}{\lang1033\langfe1033\f2\cf0  for beta}{\f2\cf0 . }\f2\cf0\par\pard\plain\ql\f2\cf0\par\pard\plain\ql{\f2\cf0 8 }\f2\cf0\par\pard\plain\ql{\f2\cf0 Now,}{\lang1033\langfe1033\f2\cf0  let's return}{\f2\cf0  to  p-values}{\lang1033\langfe1033\f2\cf0 . I}{\f2\cf0 t is important to be aware of the distinction between [statistical significance] and [substantive significance]. When the sample size is very large, a statistically significant result may not necessarily be substantively significant. Even when the regression coefficient is very close to zero, a large sample size may make it statistically significant. It means the true value of beta is unlikely to be exactly zero, but it is likely to be very }{\lang1033\langfe1033\f2\cf0 close to zero.}{\lang1033\langfe1033\f2\cf0  }\lang1033\langfe1033\f2\cf0\par\pard\plain\ql{\lang1033\langfe1033\f2\cf0 For example, suppose the estimated value of regression coeff}{\lang1033\langfe1033\f2\cf0 ici}{\lang1033\langfe1033\f2\cf0 ent }{\lang1033\langfe1033\f2\cf0 of an independent variable}{\lang1033\langfe1033\f2\cf0 ,}{\lang1033\langfe1033\f2\cf0  }{\lang1033\langfe1033\f2\cf0 x1}{\lang1033\langfe1033\f2\cf0 ,}{\lang1033\langfe1033\f2\cf0  }{\lang1033\langfe1033\f2\cf0 is 0.02}{\lang1033\langfe1033\f2\cf0 . This }{\lang1033\langfe1033\f2\cf0 could}{\lang1033\langfe1033\f2\cf0  be substantively significant or insignificant, }{\lang1033\langfe1033\f2\cf0 depending on the scales of x1 and y, }{\lang1033\langfe1033\f2\cf0 their variations}{\lang1033\langfe1033\f2\cf0 , and substantive characteristics of th}{\lang1033\langfe1033\f2\cf0 ose variables. Suppose that}{\lang1033\langfe1033\f2\cf0  }{\lang1033\langfe1033\f2\cf0 in the substantive conte}{\lang1033\langfe1033\f2\cf0 x}{\lang1033\langfe1033\f2\cf0 t, }{\lang1033\langfe1033\f2\cf0 any }{\lang1033\langfe1033\f2\cf0 absolute }{\lang1033\langfe1033\f2\cf0 value }{\lang1033\langfe1033\f2\cf0 of the coefficie}{\lang1033\langfe1033\f2\cf0 nt }{\lang1033\langfe1033\f2\cf0 below 0.}{\lang1033\langfe1033\f2\cf0 1}{\lang1033\langfe1033\f2\cf0  means }{\lang1033\langfe1033\f2\cf0 that }{\lang1033\langfe1033\f2\cf0 the relation between }{\lang1033\langfe1033\f2\cf0 x1 and y}{\lang1033\langfe1033\f2\cf0 , controlling for the other }{\lang1033\langfe1033\f2\cf0 X}{\lang1033\langfe1033\f2\cf0 s, is }{\lang1033\langfe1033\f2\cf0 negligibly}{\lang1033\langfe1033\f2\cf0  weak. Nevertheless, if the }{\lang1033\langfe1033\f2\cf0 sample size is large, then the }{\lang1033\langfe1033\f2\cf0 95% }{\lang1033\langfe1033\f2\cf0 confidence}{\lang1033\langfe1033\f2\cf0  }{\lang1033\langfe1033\f2\cf0 interval }{\lang1033\langfe1033\f2\cf0 may be very small, like between 0.01 and 0.03}{\lang1033\langfe1033\f2\cf0 , and the p-value may be smaller than }{\lang1033\langfe1033\f2\cf0 the widely used cutoff point of }{\lang1033\langfe1033\f2\cf0 0.0}{\lang1033\langfe1033\f2\cf0 5}{\lang1033\langfe1033\f2\cf0 . }{\lang1033\langfe1033\f2\cf0 Th}{\lang1033\langfe1033\f2\cf0 is}{\lang1033\langfe1033\f2\cf0  means}{\lang1033\langfe1033\f2\cf0 ,}{\lang1033\langfe1033\f2\cf0  }{\lang1033\langfe1033\f2\cf0 that}{\lang1033\langfe1033\f2\cf0 ,}{\lang1033\langfe1033\f2\cf0  }{\lang1033\langfe1033\f2\cf0 beta is unlikely to be exactly zero}{\lang1033\langfe1033\f2\cf0 , but the relation between x1 and y is negligible}{\lang1033\langfe1033\f2\cf0  in the }{\lang1033\langfe1033\f2\cf0 su}{\lang1033\langfe1033\f2\cf0 bstantive context}{\lang1033\langfe1033\f2\cf0 .}\f2\cf0\par\pard\plain\ql\f2\cf0\par\pard\plain\ql{\f2\cf0 9}\f2\cf0\par\pard\plain\ql{\f2\cf0 Special caution is needed about regression results for categorical independent variables. }{\lang1033\langfe1033\f2\cf0 If a binary variable }{\lang1033\langfe1033\f2\cf0 for a category}{\lang1033\langfe1033\f2\cf0  of }{\lang1033\langfe1033\f2\cf0 a }{\lang1033\langfe1033\f2\cf0 po}{\lang1033\langfe1033\f2\cf0 lytomous variable}{\lang1033\langfe1033\f2\cf0  is u}{\lang1033\langfe1033\f2\cf0 sed in the regression analysis}{\lang1033\langfe1033\f2\cf0 , }{\f2\cf0 the }{\lang1033\langfe1033\f2\cf0 P }{\f2\cf0 value given to the coefficient for }{\lang1033\langfe1033\f2\cf0 the}{\f2\cf0  binary variable}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  }{\lang1033\langfe1033\f2\cf0 determines}{\f2\cf0  statistical significance of the difference between the category and the reference category.  So, if the reference category is changed, the p-value for the binary variable will change}{\lang1033\langfe1033\f2\cf0 , too}{\f2\cf0 .}\f2\cf0\par\pard\plain\ql\f2\cf0\par\pard\plain\ql{\f2\cf0 10}\f2\cf0\par\pard\plain\ql{\f2\cf0 Also, in case of a }{\lang1033\langfe1033\f2\cf0 polytomous}{\f2\cf0  variable, the computer output }{\lang1033\langfe1033\f2\cf0 of the regression analysis should show }{\f2\cf0 the p-value for the difference between each category and the reference category, but not the }{\lang1033\langfe1033\f2\cf0 P }{\f2\cf0 value for the difference between two categoies that are not the reference category. In such a case, the easiest way to get the P value for the difference}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  is to do another regression analysis with a different reference category.}\f2\cf0\par\pard\plain\ql{\lang1033\langfe1033\f2\cf0 Let's look at }{\f2\cf0 another example. }{\lang1033\langfe1033\f2\cf0 A}{\f2\cf0  regression analysis of systolic blood pressure was done, with data on women only. The independent variables are age and education, }{\lang1033\langfe1033\f2\cf0 and education}{\f2\cf0  has three categories}\f2\cf0\par\pard\plain\ql\lang1033\langfe1033\f2\cf0\par\pard\plain\ql{\lang1033\langfe1033\f2\cf0 11}\lang1033\langfe1033\f2\cf0\par\pard\plain\ql{\lang1033\langfe1033\f2\cf0 Suppose that}{\f2\cf0  }{\lang1033\langfe1033\f2\cf0 first, a }{\f2\cf0 regression analysis was done using}{\lang1033\langfe1033\f2\cf0  }{\f2\cf0 [}{\f2\cf0 graduated from college]}{\lang1033\langfe1033\f2\cf0  }{\f2\cf0 as the reference category of education, and regression coefficients were obtained for the other two education categories, 8.736 for those who have not graduated from high school, and 3.976 for those who have graduated from high school}{\f2\cf0 . }{\lang1033\langfe1033\f2\cf0 T}{\f2\cf0 he P value for the 8.736 point difference between those who have not graduated from high school, and those who have graduated from college, controlling for age, was }{\f2\cf0 0.000, and the P value for the 3.976 point difference between high school graduates and college graduates}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  was }{\f2\cf0 0.051. But the P value for the difference between those who have not graduated from high schoo}{\f2\cf0 l}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  and those who ha}{\lang1033\langfe1033\f2\cf0 ve}{\f2\cf0  graduated from high school}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  was not obtained, so the statistical significance of th}{\lang1033\langfe1033\f2\cf0 e}{\f2\cf0  difference was }{\lang1033\langfe1033\f2\cf0 unknown}{\f2\cf0 .}\f2\cf0\par\pard\plain\ql{\f2\cf0 So, the second regression analysis was done}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  using [graduated from high school] as the reference category. Now the regression coefficient for those who have not graduated from }{\lang1033\langfe1033\f2\cf0 high school}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  has changed from 8.736 in the first analysis to 4.760 in the second analysis, and }{\lang1033\langfe1033\f2\cf0 its }{\f2\cf0 P value}{\lang1033\langfe1033\f2\cf0  from the second analysis}{\f2\cf0 , which was 0.009, is about the difference between those }{\lang1033\langfe1033\f2\cf0 who}{\f2\cf0  have not graduated from high school}{\lang1033\langfe1033\f2\cf0 ,}{\f2\cf0  and those who have graduated from high school.}\f2\cf0\par\pard\plain\ql\f2\cf0\par\pard\plain\ql{\f2\cf0 12}\f2\cf0\par\pard\plain\ql{\f2\cf0 this }{\lang1033\langfe1033\f2\cf0 diagram}{\f2\cf0  summarizes the process of computation of the P value. From results of the regression analysis of the data, and the null hypothesis about the regression coefficient for x}{\f2\cf0 j, the test statistic T, or upper-case T,  is obtained. On the other hand, based on some mathematical assumptions, the test statistic T, or the uppercase T, is considered to asymptotically follow the t distribution, or the lowercase }{\lang1033\langfe1033\f2\cf0 t}{\f2\cf0  distribution, with the degree of freedom, which is determined by the number of cases and the number of independent variables. By placing the test statistic T in the t-distribution, we can compute the P value, which is,  in the case of two-sided test, the probability that the absolute value of test statistic T is greater than the absolute value of the obtained T, if the null hypothesis holds true.}{\lang1033\langfe1033\f2\cf0  }{\lang1033\langfe1033\f2\cf0 A c}{\lang1033\langfe1033\f2\cf0 onfidence interval}{\lang1033\langfe1033\f2\cf0  for beta j can be obtained }{\lang1033\langfe1033\f2\cf0 in a similar way, by setting beta j as unknown, instead of zero.}\f2\cf0\par}